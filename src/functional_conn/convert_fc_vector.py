#!/usr/bin/env python3
"""
Convert functional connectivity matrices to vectors for machine learning analysis.

This script processes Fisher Z-transformed FC matrices generated by fisher_z_fc.py and converts them
to vectors following the same logic as the original convert_matrices_to_vectors.py:
- Extract lower triangle (excluding diagonal)

The script expects input structure:
  input_path/Schaefer{n_rois}/{subject}_Schaefer{n_rois}_FC_z.csv

And creates output structure:
  output_path/Schaefer{n_rois}/individual/{subject}_Schaefer{n_rois}_FC_Z.npy
"""

import argparse
import numpy as np
import pandas as pd
from pathlib import Path
import logging
from typing import List, Optional, Dict

from src.path_config import load_dataset_config, load_paths_config, resolve_dataset_roots

# Configure logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)


class FisherZMatrixToVectorConverter:
    """Convert Fisher Z-transformed FC matrices to vectors."""
    
    def __init__(self, input_path: str, sublist_file: str, output_path: str, dataset_name: str, n_rois: int = 400):
        """
        Initialize the converter.
        
        Args:
            input_path: Path to directory containing Fisher Z FC matrices
            sublist_file: Path to subject list file (sublist.txt)
            output_path: Path to output directory for vector matrices
            dataset_name: Name of the dataset (e.g., ABCD, CCNP, HCPD, PNC, EFNY)
            n_rois: Number of ROIs (100, 200, 400)
        """
        self.input_path = Path(input_path)
        self.sublist_file = Path(sublist_file)
        self.output_path = Path(output_path)
        self.dataset_name = dataset_name
        self.n_rois = n_rois
        
        # Create output directory if it doesn't exist
        self.output_path.mkdir(parents=True, exist_ok=True)
        
        logger.info(f"Input path: {self.input_path}")
        logger.info(f"Subject list: {self.sublist_file}")
        logger.info(f"Output path: {self.output_path}")
        logger.info(f"Dataset: {self.dataset_name}")
        logger.info(f"Number of ROIs: {self.n_rois}")
    
    def load_subject_list(self) -> List[str]:
        """Load subject list from file."""
        try:
            with open(self.sublist_file, 'r', encoding='utf-8') as f:
                subjects = [line.strip() for line in f if line.strip()]
            logger.info(f"Loaded {len(subjects)} subjects from {self.sublist_file}")
            return subjects
        except Exception as e:
            logger.error(f"Failed to load subject list from {self.sublist_file}: {e}")
            raise
    
    def extract_vector(self, matrix: np.ndarray) -> np.ndarray:
        """Extract vector using lower triangle (excluding diagonal)."""
        if matrix.ndim != 2 or matrix.shape[0] != matrix.shape[1]:
            raise ValueError(f"Matrix must be square, got shape {matrix.shape}")
        
        # Extract lower triangle elements (excluding diagonal)
        m = matrix.shape[0]
        lower_mask = np.tril(np.ones((m, m), dtype=bool), k=-1)
        vector = matrix[lower_mask]
        
        logger.debug(f"Matrix {matrix.shape} -> vector {vector.shape}")
        return vector
    
    def load_fisher_z_matrix(self, subject_id: str) -> Optional[np.ndarray]:
        """Load Fisher Z-transformed FC matrix for a subject."""
        # Expected file path from fisher_z_fc.py output
        matrix_file = self.input_path / f"Schaefer{self.n_rois}" / f"{subject_id}_Schaefer{self.n_rois}_FC_z.csv"
        
        if not matrix_file.exists():
            logger.warning(f"Fisher Z matrix not found: {matrix_file}")
            return None
        
        try:
            # Load as CSV (as saved by fisher_z_fc.py)
            matrix = np.loadtxt(matrix_file, delimiter=",")
            logger.debug(f"Loaded Fisher Z matrix for {subject_id}: {matrix.shape}")
            return matrix
        except Exception as e:
            logger.error(f"Failed to load Fisher Z matrix for {subject_id}: {e}")
            return None
    
    def convert_matrix_to_vector(self, matrix: np.ndarray) -> np.ndarray:
        """Convert matrix to vector."""
        return self.extract_vector(matrix)
    
    def save_vector_matrix(self, vector: np.ndarray, subject_id: str) -> None:
        """Save vector matrix as individual .npy file."""
        # Create output directory structure: output_path/Schaefer{n_rois}/individual/
        output_dir = self.output_path / f"Schaefer{self.n_rois}" / "individual"
        output_dir.mkdir(parents=True, exist_ok=True)
        
        # Save vector
        output_file = output_dir / f"{subject_id}_Schaefer{self.n_rois}_FC_Z.npy"
        np.save(output_file, vector)
        logger.debug(f"Saved vector for {subject_id}: {output_file}")
    
    def process_all_subjects(self, subjects: List[str]) -> tuple:
        """
        Process all subjects and convert their Fisher Z matrices to vectors.
        
        Args:
            subjects: List of subject IDs
            
        Returns:
            Tuple containing:
            - Dictionary with subject IDs as keys and vectors as values
            - List of successfully processed subject IDs
            - List of subjects missing Fisher Z matrices
        """
        subject_vectors = {}
        valid_subjects = []
        missing_subjects = []
        
        for i, subject_id in enumerate(subjects):
            logger.info(f"Processing subject {i+1}/{len(subjects)}: {subject_id}")
            
            # Load Fisher Z matrix
            matrix = self.load_fisher_z_matrix(subject_id)
            if matrix is None:
                missing_subjects.append(subject_id)
                continue
            
            try:
                # Convert to vector
                vector = self.convert_matrix_to_vector(matrix)
                subject_vectors[subject_id] = vector
                valid_subjects.append(subject_id)
                
                # Save individual vector file
                self.save_vector_matrix(vector, subject_id)
                
                logger.info(f"Processed {subject_id}: vector {vector.shape}")
                
            except Exception as e:
                logger.error(f"Error processing subject {subject_id}: {e}")
                missing_subjects.append(subject_id)
                continue
        
        logger.info(f"Successfully processed {len(valid_subjects)} out of {len(subjects)} subjects")
        logger.info(f"Found {len(missing_subjects)} subjects missing Fisher Z matrices")
        return subject_vectors, valid_subjects, missing_subjects
    
    def save_summary_results(self, subject_vectors: Dict[str, np.ndarray], 
                           valid_subjects: List[str], missing_subjects: List[str]):
        """Save summary results and statistics."""
        # Create output directory
        output_dir = self.output_path / f"Schaefer{self.n_rois}"
        output_dir.mkdir(parents=True, exist_ok=True)
        
        # Save valid subjects list
        valid_subjects_file = output_dir / f"valid_subjects_Schaefer{self.n_rois}.txt"
        with open(valid_subjects_file, 'w', encoding='utf-8') as f:
            for subject_id in valid_subjects:
                f.write(f"{subject_id}\n")
        logger.info(f"Saved valid subjects list to {valid_subjects_file}")
        
        # Save missing subjects list
        if missing_subjects:
            missing_subjects_file = output_dir / f"missing_subjects_Schaefer{self.n_rois}.txt"
            with open(missing_subjects_file, 'w', encoding='utf-8') as f:
                for subject_id in missing_subjects:
                    f.write(f"{subject_id}\n")
            logger.info(f"Saved missing subjects list to {missing_subjects_file}")
        
        # Create combined matrix: subjects Ã— features
        if valid_subjects and subject_vectors:
            first_subject = valid_subjects[0]
            first_vector = subject_vectors[first_subject]
            n_features = first_vector.shape[0]
            
            # Initialize combined matrix
            combined_matrix = np.zeros((len(valid_subjects), n_features))
            
            # Fill matrix in sublist order
            for i, subject_id in enumerate(valid_subjects):
                if subject_id in subject_vectors:
                    combined_matrix[i, :] = subject_vectors[subject_id]
                else:
                    logger.warning(f"Subject {subject_id} not found in processed vectors")
            
            # Save combined matrix
            combined_file = output_dir / f"{self.dataset_name}_Schaefer{self.n_rois}_FC_matrix.npy"
            np.save(combined_file, combined_matrix)
            logger.info(f"Saved combined FC matrix: {combined_matrix.shape} to {combined_file}")
            
            # Save vector dimensions info
            info_file = output_dir / f"vector_info_Schaefer{self.n_rois}.txt"
            with open(info_file, 'w', encoding='utf-8') as f:
                f.write(f"Dataset: {self.dataset_name}\n")
                f.write(f"Number of ROIs: {self.n_rois}\n")
                f.write(f"Total subjects: {len(valid_subjects) + len(missing_subjects)}\n")
                f.write(f"Valid subjects: {len(valid_subjects)}\n")
                f.write(f"Missing subjects: {len(missing_subjects)}\n")
                f.write(f"Vector dimension: {n_features} features\n")
                f.write(f"Combined matrix shape: {combined_matrix.shape}\n")
                f.write(f"Combined matrix file: {combined_file.name}\n")
            logger.info(f"Saved vector info to {info_file}")
    
    def run(self):
        """Execute the complete conversion pipeline."""
        logger.info(f"Starting Fisher Z matrix-to-vector conversion for {self.dataset_name}")
        
        # Load subject list
        subjects = self.load_subject_list()
        
        # Process all subjects
        subject_vectors, valid_subjects, missing_subjects = self.process_all_subjects(subjects)
        
        # Save summary results
        self.save_summary_results(subject_vectors, valid_subjects, missing_subjects)
        
        logger.info("Fisher Z matrix-to-vector conversion completed successfully")


def main():
    """Main function to run the Fisher Z matrix-to-vector conversion."""
    parser = argparse.ArgumentParser(
        description="Convert Fisher Z-transformed FC matrices to vectors for machine learning analysis",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
    # Convert EFNY Fisher Z matrices to vectors for Schaefer400
    python convert_fc_vector.py --input_path /path/to/EFNY/functional_conn_z/rest --sublist_file /path/to/sublist.txt --output_path /path/to/EFNY/fc_vector --dataset_name EFNY --n_rois 400
    
    # Convert with custom ROI number
    python convert_fc_vector.py --input_path /path/to/matrices --sublist_file subjects.txt --output_path /path/to/output --dataset_name CUSTOM --n_rois 200
        """
    )
    
    parser.add_argument(
        "--input_path",
        type=str,
        required=False,
        help="Path to directory containing Fisher Z FC matrices (e.g., /path/to/dataset/functional_conn_z/rest)"
    )
    
    parser.add_argument(
        "--sublist_file",
        type=str,
        required=False,
        help="Path to subject list file (sublist.txt)"
    )
    
    parser.add_argument(
        "--output_path",
        type=str,
        required=False,
        help="Path to output directory for vector matrices (e.g., /path/to/dataset/fc_vector)"
    )
    
    parser.add_argument(
        "--dataset_name",
        type=str,
        required=False,
        choices=['ABCD', 'CCNP', 'HCPD', 'PNC', 'EFNY', 'CUSTOM'],
        help="Name of the dataset"
    )
    
    parser.add_argument(
        "--n_rois",
        type=int,
        default=400,
        choices=[100, 200, 400],
        help="Number of ROIs (100, 200, 400)"
    )
    
    parser.add_argument(
        "--verbose",
        action="store_true",
        help="Enable verbose logging"
    )
    parser.add_argument("--dataset", type=str, default=None)
    parser.add_argument("--config", dest="paths_config", type=str, default="configs/paths.yaml")
    parser.add_argument("--dataset-config", dest="dataset_config", type=str, default=None)
    
    args = parser.parse_args()

    if args.input_path is None or args.sublist_file is None or args.output_path is None or args.dataset_name is None:
        if not args.dataset:
            raise ValueError("Missing --dataset (required when defaults are used).")
        repo_root = Path(__file__).resolve().parents[2]
        paths_cfg = load_paths_config(args.paths_config, repo_root=repo_root)
        roots = resolve_dataset_roots(paths_cfg, dataset=args.dataset)
        dataset_cfg = load_dataset_config(
            paths_cfg,
            dataset_config_path=args.dataset_config,
            repo_root=repo_root,
        )
        files_cfg = dataset_cfg.get("files", {})
        sublist_rel = files_cfg.get("sublist_file")
        if not sublist_rel:
            raise ValueError("Missing files.sublist_file in dataset config.")

        args.input_path = args.input_path or str(roots["interim_root"] / "functional_conn_z" / "rest")
        args.sublist_file = args.sublist_file or str(roots["processed_root"] / sublist_rel)
        args.output_path = args.output_path or str(roots["processed_root"] / "fc_vector")
        args.dataset_name = args.dataset_name or args.dataset
    
    # Set logging level
    if args.verbose:
        logger.setLevel(logging.DEBUG)
    
    # Create and run the converter
    converter = FisherZMatrixToVectorConverter(
        args.input_path, 
        args.sublist_file, 
        args.output_path, 
        args.dataset_name,
        args.n_rois
    )
    converter.run()


if __name__ == "__main__":
    main()
