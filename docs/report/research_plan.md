# 研究课题：基于双向稀疏协变模式的执行功能神经本体论重构：从原始行为指标到动态脑网络

## 一、 研究背景与核心范式革命

### 1.1 核心痛点：心理测量学与神经生物学的断层
传统的认知神经科学遵循“构念-测量-定位”的路径（例如：先假设存在“抑制控制”因子，再用SST任务测量，最后寻找对应脑区）。然而，这种路径存在根本性缺陷：
*   **人工聚合的假象**：传统的因子分析（EFA/CFA）强行将不同任务的指标聚合为“潜变量”，这往往掩盖了特定任务指标（如反应时变异性、错误类型）所携带的独特神经生物学信息。
*   **映射失效**：研究表明，心理学定义的“因子”往往无法映射到单一的脑网络，而全脑连接模式往往能解释比单一因子更多的行为方差。

### 1.2 新范式：Raw-to-Raw 的数据驱动本体论
本研究提出一种彻底的**“反还原论”**范式：
*   **输入端去假设化**：不再预先计算“抑制分数”或“转换分数”，而是将**所有原始行为指标**（Raw Metrics，如特定条件的RT均值、RT标准差、漏报率、虚报率等）直接纳入模型。
*   **双向稀疏筛选**：利用**双向稀疏典型相关分析（Dual-Sparse CCA）**，让算法同时在“全脑连接空间”和“高维行为空间”中自动筛选出具有最大协变关系的特征子集。
*   **本体论重定义**：每一个筛选出的稳健协变模式（Covariance Mode），就是一个被神经机制验证过的“生物-行为单元”（Bio-behavioral Unit），它们将构成新的EF本体论。

---

## 二、 核心科学问题

1.  **发现层面（Discovery）**：当完全抛弃心理学因子假设，让原始行为指标与全脑连接直接碰撞时，会涌现出哪些**跨任务的共变模式**？
    *   *假设*：可能发现基于“处理速度/信噪比”的通用模式（General Efficiency Mode），以及基于“网络切换代价”的特定模式，而非传统的“抑制/刷新/转换”三分法。
2.  **定义层面（Definition）**：如何根据被算法选中的原始行为指标组合（例如：Stroop不一致RT + Nback虚报率）和对应的脑网络拓扑属性，对新的认知成分进行**机制性命名**？
3.  **发育层面（Development）**：这些协变模式在6-22岁的发育过程中是如何分化（Differentiate）的？是先形成全脑整合模式，再分化出特异性回路吗？

---

## 三、 研究对象与数据

### 3.1 被试
*   **样本**：394名发育期青少年（6～22岁），排除神经精神疾病史。
*   **数据质量控制**：严格控制头动（FD < 0.2mm），对高头动被试进行剔除或擦除处理（Scrubbing）。

### 3.2 行为数据（特征矩阵 $Y$：$N \times P_{behavior}$）
不使用合成的一级分数，而是提取**细粒度（Fine-grained）原始指标**（当前版本为135个特征，来自 `data/EFNY/table/metrics/EFNY_beh_metrics.csv`）：

**行为指标与样本覆盖（以 `sublist.txt` 的394名fMRI样本为基准）**：
- **维度**：$P_{behavior}=135$
- **有任意行为指标（135列中任意一列非缺失）**：382/394（97.0%）
- **全指标无缺失（135列全部非缺失）**：123/394（31.2%）
- **任务级完整（对每个任务域至少有1个指标非缺失）**：224/394（56.9%）

| 认知任务域 | 具体任务 | 行为指标 | 有影像数据的人中有该任务数据的人数 |
|------------|----------|----------|-----------------------------------|
| **反应抑制** | SST (Stop Signal Task) | 8个指标（Accuracy/RT/SSRT/SSD等） | 381 |
| **持续注意/GoNoGo** | CPT (Continuous Performance Task) | 8个指标（d', Accuracy, Go/NoGo等） | 378 |
| **冲突控制** | Flanker | 9个指标（Congruent/Incongruent/Contrast等） | 381 |
| **冲突控制** | Color Stroop | 9个指标（Congruent/Incongruent/Contrast等） | 381 |
| **情绪冲突控制** | Emotion Stroop | 9个指标（Congruent/Incongruent/Contrast等） | 375 |
| **任务切换** | Emotion Switch | 9个指标（Repeat/Switch/Switch Cost等） | 381 |
| **任务切换** | Dimension Switch (DT) | 9个指标（Repeat/Switch/Switch Cost等） | 373 |
| **工作记忆** | oneback_number | 6个指标（ACC/RT/Hit/FA/d'） | 375 |
| **工作记忆** | twoback_number | 6个指标（ACC/RT/Hit/FA/d'） | 372 |
| **空间工作记忆** | oneback_spatial | 6个指标（ACC/RT/Hit/FA/d'） | 373 |
| **空间工作记忆** | twoback_spatial | 6个指标（ACC/RT/Hit/FA/d'） | 367 |
| **情绪工作记忆** | oneback_emotion | 6个指标（ACC/RT/Hit/FA/d'） | 373 |
| **情绪工作记忆** | twoback_emotion | 6个指标（ACC/RT/Hit/FA/d'） | 364 |
| **认知灵活性** | DCCS (Dimensional Change Card Sort) | 9个指标（Repeat/Switch/Switch Cost等） | 377 |
| **抑制控制** | GNG (Go/NoGo) | 8个指标（d', Accuracy, Go/NoGo等） | 380 |
| **加工速度/执行控制** | FZSS | 8个指标（Miss/FA/Correct RT等） | 379 |
| **规划/路径搜索** | KT (Knights Tour) | 5个指标（Accuracy/RT等） | 255 |
| **其他（任务名以数据表为准）** | ZYST | 8个指标（T0/T1等） | 376 |

**总计**：18个认知任务域，135个原始行为指标

**数据质量控制结果**：
- **样本匹配**：394名fMRI被试中，382名（97.0%）具有任意行为指标数据
- **全指标无缺失**：123名被试（31.2%）在135个指标上均无缺失
- **任务级完整**：224名被试（56.9%）在18个任务域上均至少有1个指标非缺失
- **质量控制指标**：meanFD已成功整合，用于后续头动控制分析


### 3.3 影像数据（特征矩阵 $X$：$N \times P_{brain}$）
*   **模态**：静息态fMRI（rs-fMRI）。
*   **数据质量控制**：严格控制头动（FD < 0.2mm），对高头动被试进行剔除或擦除处理（Scrubbing）。已计算meanFD指标并整合到行为数据表中，用于后续头动控制分析。
*   **特征工程与降维策略（至关重要）**：鉴于N=394，严禁使用体素级（Voxel-wise）特征。
    *   采用 **Schaefer 400 Parcellation** (或 Glasser 360) 将全脑划分为400个ROI。
    *   计算ROI间的Pearson相关矩阵，并提取**网络内（Within-network）**和**网络间（Between-network）**的平均连接强度（基于Yeo 7/17网络模板）。
    *   最终脑特征数控制在 **50-100个** 左右，以匹配行为数据的维度，避免维度灾难。

---

## 四、 方法论：双向稀疏与稳定性选择

这是本研究对抗“小样本过拟合”的核心技术路线。

### 4.1 核心算法：Dual-Sparse CCA (sCCA)
由于 $P_{brain} (4950) \gg N (394)$，我们将对比三种处理“高维-高维”关系的方法。

#### 方法 1：正则化典型相关分析 (Regularized CCA / rCCA)
*   **角色**：作为**基线模型**（替代无法运行的标准CCA）。
*   **原理**：标准CCA要求样本量大于特征数，否则矩阵不可逆。rCCA 通过在协方差矩阵对角线上加入两个参数 ($\lambda_1, \lambda_2$，即 L2 Ridge Penalty)，使得在 $P \gg N$ 时也能求解。
*   **实现要点（cca-zoo rCCA）**：
    *   **潜在维度**：`latent_dimensions`（对应本代码里的 `n_components`）。决定提取多少对典型变量。
    *   **正则化参数**：`c`（可为 `float` 或 `Iterable`）。本项目使用两视图分别设置：`c=[c_X, c_Y]`。
        *   直观理解：`c` 越大，正则化越强，越能提升数值稳定性但可能削弱相关性。
        *   协方差混合形式：`(1 - c) * Cov + c * I`。
    *   **PCA 求解**：`pca=True`（默认开启），对高维 FC 特征能显著提升稳定性与效率。
    *   **数值稳定参数**：`eps`，用于避免矩阵不可逆/数值不稳定。
*   **优点**：
    *   不需要 PCA 降维，直接输入 4950 条边。
    *   利用了所有信息，不会丢失方差。
*   **缺点**：
    *   **结果不稀疏**：它会给所有 4950 条边都分配一个非零权重（Weight），导致结果解释像“全脑弥散的雾”，很难定位到具体回路。
*   **预期结果**：典型相关系数很高，但很难画出清晰的脑网络图。

##### rCCA 的超参数选择（Adaptive rCCA）
为避免手工指定 `latent_dimensions` 与正则化强度，本项目实现 **`adaptive_rcca`**：
*   **内层交叉验证（internal CV）**：在训练数据上同时搜索：
    *   `n_components`（潜在维度数）
    *   `c_X, c_Y`（两视图正则化强度）
*   **选择准则**：默认以验证集上的平均典型相关系数（`canonical_correlation`）为目标。
*   **置换检验策略**：置换检验中固定真实数据选出的最优 `(n_components, c_X, c_Y)`，保证置换分布与观测统计量可比（避免把“超参调优收益”也带入置换分布）。

#### 方法 2：偏最小二乘相关 (PLS Correlation)
*   **角色**：作为**稳健对照模型**。
*   **原理**：PLS 寻找的是两组变量**协方差（Covariance）**最大的方向，而非相关系数（Correlation）。它天生支持高维数据，不需要矩阵求逆。
*   **优点**：
    *   计算极快，非常稳定。
    *   在神经影像领域应用最广泛（如HCP研究），适合发现“整体效应”。
*   **缺点**：
    *   倾向于提取“方差大”的特征（如全脑整体连接强度的波动），可能掩盖细微的特异性回路。
*   同样不具备稀疏性，权重往往全脑分布。

#### 方法 3：双向稀疏典型相关分析 (Sparse CCA / sCCA) —— **本研究核心**
*   **角色**：作为**本体论发现模型**。
*   **原理**：在最大化相关性的同时，加入 **L1 惩罚项 (Lasso penalty)**。这会强制大部分无关特征的权重变为 **0**。
*   **核心优势**：
    *   **自动特征选择**：它会从 4950 条边中只留下 50-100 条最重要的边；从 35 个行为指标中只留下 5-8 个核心指标。
    *   **去伪存真**：直接定义出“由哪些脑连接支持哪些行为”的精确模块。
*   **实施关键**：必须配合 **稳定性选择 (Stability Selection)**（见下文），否则单词运行的结果可能不稳定。

#### 方法 0：必须加入的对照 —— rCCA vs. sCCA 的“弥散-稀疏”判别
为避免把“稀疏性”当作先验信仰，本研究将把 **rCCA** 与 **sCCA** 作为并行的核心模型族进行对照分析：
*   若 **rCCA 的典型相关系数显著高于 sCCA**，且跨重采样稳定，提示脑-行为关系更可能是“弥散型”的（整体轴/梯度主导），应将解释重点放在宏观组织原则（例如梯度、网络级连接）而非少数边。
*   若 **sCCA 仅牺牲少量相关性**，却能产生高度可解释、跨重采样稳定的稀疏特征集合，则支持“本体论重构”的核心论点：存在可被稳定筛选的生物-行为单元。
*   结论将以“相关性（泛化）—可解释性（稀疏与稳定）”的权衡曲线呈现，而非只报告单一最优模型。

---

### 4.2 鲁棒性验证：稳定性选择 (Stability Selection)
为了回答“结果是否可重复”的质疑，不依赖单一模型的输出，而是采用**重采样投票机制**：
1.  **重采样**：进行 **1,000次 Bootstrap** 抽样（每次随机抽取80%样本）。
2.  **重复建模**：在每次抽样数据上运行 Dual-Sparse CCA。
3.  **概率计算**：计算每个行为指标和脑连接被筛选进入模型（权重 $\neq 0$）的概率。
4.  **最终定义**：仅保留那些**在 >70% 的抽样中都稳定出现**的行为指标和脑网络。只有这些“幸存者”才被用于定义新的EF成分。

### 4.3 结果预判：单一主轴 vs. 多重模态
现实数据往往呈现“单一主轴吸走大部分方差”的结构：
*   参考 Smith et al. (2015) 的 “Positive–Negative Mode”、Chopra et al. (2024) 的整体认知预测轴，以及 Nicolaisen-Sobesky et al. (2022) 的发现：第一个潜在维度往往非常强且可复制，但后续维度常不稳定。
*   因此，本研究将把“只能发现一个强 Mode（一般能力/一般执行功能）”作为主要可接受结论之一，并将其视为对传统多维EF分类的关键证据，而非失败。

### 4.4 正交化处理与层级回归：为 Mode 2 创造信噪比
为了在强主轴存在时仍有机会提取更特异的模式（例如切换代价/冲突控制特异性）：
*   在进入CCA之前，考虑在行为矩阵中先回归掉一般能力相关成分（例如反应时均值或基于多任务的第一主成分），迫使模型关注残差结构。
*   在脑特征侧同步做层级回归（例如回归全局信号/整体连接强度摘要），以降低“整体轴”对后续维度的挤压。
*   该步骤将作为显式分析分支呈现：先报告“原始Y”的Mode 1，再报告“去主轴残差Y”的潜在 Mode 2，以避免过度解释不稳定维度。

### 4.5 发育效应建模
*   **脑龄差（Brain Age Gap, BAG）**：训练机器学习模型预测生理年龄，计算 BAG = 预测年龄 - 实际年龄。
*   **关联分析**：检验挖掘出的 EF 协变成分（Component Scores）与 BAG 的关系，以剥离单纯的生理成熟效应，寻找特异性的神经发育标志物。

### 4.6 发育视角的深化：滑动窗口 CCA (Sliding Window CCA)
年龄不应仅作为协变量被简单回归掉。本研究将实现滑动窗口策略刻画“分化假说”：
*   将样本按年龄排序，设定窗口（例如 N=150）与步长（例如 20），对每个窗口独立运行 rCCA 与 sCCA。
*   记录每个窗口中 Mode 1/Mode 2 的相关性、解释方差、稳定性指标随年龄的变化趋势。
*   若分化假说成立，预期 Mode 1 的解释力随年龄下降，而特异模式（潜在 Mode 2）的解释力或网络特异性随年龄上升。

---

## 五、 预期成果与理论重构

### 5.1 预期发现的“神经认知模态”（Neurocognitive Modes）
预计将发现2-3个稳健的典型模式（Canonical Modes）：

*   **Mode 1: 全局神经整合效率（Global Integration Efficiency）**
    *   **行为特征**：加载在所有高负荷任务（2-back, Incongruent trials）的**准确率**和**低RT变异性**上。
    *   **神经特征**：全脑“多重需求网络”（MDN）内部连接强度高，且与感觉运动网络（Sensorimotor）解耦。
    *   **本体论定义**：**一般性执行加工容量（General Executive Capacity）**。

*   **Mode 2: 动态重构代价（Dynamic Reconfiguration Cost）**
    *   **行为特征**：特异性加载在任务切换（DCCS, EmotionSwitch）的**差分值**（Switch Cost）上。
    *   **神经特征**：额顶控制网络（FPCN）与默认网络（DMN）之间的连接灵活性（非静态连接，而是功能连接的动态变异性）。
    *   **本体论定义**：**网络状态切换灵活性（Network State Flexibility）**。

### 5.2 理论贡献
1.  **去伪存真**：证明某些经典的心理学指标（可能是Stroop干扰效应）在神经层面并不存在稳定的单一对应物，而是多个过程的混合。
2.  **发育分化验证**：证明低龄组（6-12岁）的EF主要由Mode 1（通用效率）主导，而高龄组（16-22岁）才涌现出独立的Mode 2（灵活切换），支持**功能分化假说（Differentiation Hypothesis）**。

---

## 六、 可行性与风险管理（针对N=394）

| 潜在风险 | 解决方案 |
| :--- | :--- |
| **维度灾难** (p > N) | **降维 + 稀疏**：脑特征降至 ROI/Network 级别 (<100特征)；使用双向 L1 正则化。 |
| **过拟合** (Marek et al., 2022) | **稳定性选择**：不看单次结果，只看 1000 次 Bootstrap 的共识结果（Consensus）。 |
| **空间自相关假阳性** | **Spin Test**：在评估脑图谱拓扑属性时，使用旋转零模型生成 10,000 个置换数据进行显著性检验。 |
| **行为指标共线性** | sCCA 对共线性处理较好（类似于 Lasso），它会倾向于从共线指标中选出一个代表，或者同时选中。 |
| **数据质量控制** | **预处理验证**：已建立完整的数据预处理管道，包括行为数据与rsfMRI QC数据的合并（meanFD指标），确保437名被试同时具有高质量的行为和影像数据。 |

## 七、 行为指标的“原生态”陷阱与稳定性阈值的改进
Raw Metrics 的高共线性会干扰稳定性选择的解释：
*   多个高度相关的行为指标（例如 1-back RT 与 2-back RT）可能在不同bootstrap中“轮流入选”，导致单个指标的入选频率被稀释，从而出现假阴性。
*   为降低该风险，本研究将增加两类改进分支：
    *   **行为指标聚类/成组解释**：在稳定性选择前对行为指标做相关性聚类；稳定性报告允许以“指标簇”作为最小解释单元，而非强制单指标。
    *   **阈值敏感性分析**：除 >70% 的主阈值外，同时报告 50% 与 90% 阈值下的“稳定核心”与“保守核心”，并解释其差异。

---

### 总结
本方案将原本风险极高的“全脑盲搜”转化为了一项**技术严谨、假设大胆**的方法学研究。通过**“Raw Metrics + Dual Sparsity + Stability Selection”**的组合拳，你不仅规避了小样本的统计陷阱，更从根本上挑战了现有的心理学分类体系，有望提出一套真正具有生物学效度（Biological Validity）的执行功能新理论。

---

## 附录：数据处理与质量控制结果

### 行为数据预处理结果
- **原始行为数据**：583条记录（包含重复测量）
- **fMRI子表（sublist）**：394名被试（6-22岁）
- **fMRI子表中具有任意行为指标**：382名被试
- **全指标无缺失（135列）**：123名被试
- **任务级完整（18个任务域均至少1列非缺失）**：224名被试

### 关键质量控制指标
- **fMRI与行为数据匹配率**：382/394（97.0%）
- **全指标无缺失比例**：123/394（31.2%）
- **任务级完整比例**：224/394（56.9%）
- **meanFD整合**：rsfMRI头动指标已成功合并到行为数据表中，用于后续头动控制
- **数据质量评估**：任务覆盖存在不均衡（例如 KT 任务覆盖较低），因此后续分析将同时报告“全指标分析（含缺失插补）”与“任务级完整子样本分析”。
